{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split,cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor,ExtraTreesRegressor,GradientBoostingRegressor,AdaBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso\n",
    "from grid_search_helper import EstimatorSelectionHelper\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('mydata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_dataframes_for_points(df):\n",
    "    \"\"\"\n",
    "    makes different dataframes that only have data from one surge point\n",
    "    \"\"\"\n",
    "    point_list = [0, 1, 2, 3, 14, 15, 16, 12, 13, 24, 25, 26, 27, 28, 17, 29]\n",
    "    return [df[df.point == point].reset_index(drop=True)[:31184] for point in point_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_0,df_1,df_2,df_3,df_14,df_15,df_16,df_12,df_13,df_24,df_25,df_26,\\\n",
    "                                                        df_27,df_28,df_17,df_29 = build_dataframes_for_points(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "array_0 = np.array([df_0.surge[i:i+60] for i in xrange(len(df_0.surge)-60)])\n",
    "array_0 = array_0[:,::-1]\n",
    "#make a small hold out sample to conserve the timeseries nature of this, I'll graph it later\n",
    "hold_out_array = array_0[-500:,:]\n",
    "y_hold_out = hold_out_array[:,0]\n",
    "X_hold_out = hold_out_array[:,3:]\n",
    "\n",
    "# this is for the classical model training and testing\n",
    "training_testing_array = array_0[:-500,:]\n",
    "y_0 = training_testing_array[:,0]\n",
    "X_0 = training_testing_array[:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_0, y_0, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ran_forest = RandomForestRegressor(n_estimators=100)\n",
    "# ran_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 'Random Forest:',np.mean((ran_forest.predict(X_test) - y_test) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20,5))\n",
    "# plt.plot(ran_forest.predict(X_hold_out)[:300],label='3 min forecast')\n",
    "# plt.plot(y_hold_out[:300],label='true 0')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ex_trees = ExtraTreesRegressor(n_estimators=100)\n",
    "ex_trees.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'Extra Trees:',np.mean((ex_trees.predict(X_test) - y_test) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(ex_trees.predict(X_hold_out)[:300],label='3 min forecast')\n",
    "plt.plot(y_hold_out[:300],label='true 0')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# doing grid searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models1 = {'LinearRegression':LinearRegression(),\n",
    "           'Ridge':Ridge(),\n",
    "           'Lasso':Lasso(),\n",
    "           'ExtraTreesRegressor':ExtraTreesRegressor(),\n",
    "           'RandomForestRegressor':RandomForestRegressor(),\n",
    "           'AdaBoostRegressor':AdaBoostRegressor(),\n",
    "           'GradientBoostingRegressor':GradientBoostingRegressor()}\n",
    "\n",
    "params1 = {'LinearRegression':{},\n",
    "           'Ridge':{'alpha':[0.001, 0.01, 0.1, 1.0]},\n",
    "           'Lasso':{'alpha':[0.001, 0.01, 0.1, 1.0]},\n",
    "           'ExtraTreesRegressor':{'n_estimators':[8,16,32,64,128]},\n",
    "           'RandomForestRegressor':{'n_estimators':[8,16,32,64,128]},\n",
    "           'AdaBoostRegressor':{'n_estimators':[8,16,32,64,128],'learning_rate':[0.6,0.8,1.0]},\n",
    "           'GradientBoostingRegressor':{'n_estimators':[8,16,32,64,128],'learning_rate':[0.6,0.8,1.0]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for GradientBoostingRegressor.\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for Ridge.\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for LinearRegression.\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for AdaBoostRegressor.\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for RandomForestRegressor.\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for ExtraTreesRegressor.\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for Lasso.\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:  3.8min finished\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    2.2s finished\n"
     ]
    }
   ],
   "source": [
    "helper1 = EstimatorSelectionHelper(models1, params1)\n",
    "helper1.fit(X_train, y_train, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "grid_search_helper.py:37: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  df = pd.concat(rows, axis=1).T.sort([sort_by], ascending=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>alpha</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.848211</td>\n",
       "      <td>0.862127</td>\n",
       "      <td>0.87351</td>\n",
       "      <td>0.0104309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.845945</td>\n",
       "      <td>0.858913</td>\n",
       "      <td>0.869744</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.84448</td>\n",
       "      <td>0.860318</td>\n",
       "      <td>0.872867</td>\n",
       "      <td>0.0117674</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.841134</td>\n",
       "      <td>0.854674</td>\n",
       "      <td>0.869205</td>\n",
       "      <td>0.0121925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.838715</td>\n",
       "      <td>0.854059</td>\n",
       "      <td>0.868475</td>\n",
       "      <td>0.0118229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.837991</td>\n",
       "      <td>0.852692</td>\n",
       "      <td>0.868398</td>\n",
       "      <td>0.0124164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.83582</td>\n",
       "      <td>0.85235</td>\n",
       "      <td>0.868462</td>\n",
       "      <td>0.0129344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.831924</td>\n",
       "      <td>0.847105</td>\n",
       "      <td>0.860638</td>\n",
       "      <td>0.0120372</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.82505</td>\n",
       "      <td>0.830992</td>\n",
       "      <td>0.839034</td>\n",
       "      <td>0.00517329</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.823254</td>\n",
       "      <td>0.831537</td>\n",
       "      <td>0.839264</td>\n",
       "      <td>0.00555201</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>0.821647</td>\n",
       "      <td>0.844716</td>\n",
       "      <td>0.860482</td>\n",
       "      <td>0.0150916</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.821635</td>\n",
       "      <td>0.832351</td>\n",
       "      <td>0.841665</td>\n",
       "      <td>0.00660997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.818883</td>\n",
       "      <td>0.838403</td>\n",
       "      <td>0.855954</td>\n",
       "      <td>0.0149617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.818779</td>\n",
       "      <td>0.825613</td>\n",
       "      <td>0.83594</td>\n",
       "      <td>0.00639065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.817493</td>\n",
       "      <td>0.82569</td>\n",
       "      <td>0.834177</td>\n",
       "      <td>0.00658899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.8135</td>\n",
       "      <td>0.824721</td>\n",
       "      <td>0.837865</td>\n",
       "      <td>0.00889868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.812284</td>\n",
       "      <td>0.822555</td>\n",
       "      <td>0.834493</td>\n",
       "      <td>0.00897273</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.812275</td>\n",
       "      <td>0.822483</td>\n",
       "      <td>0.834525</td>\n",
       "      <td>0.00900215</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.812273</td>\n",
       "      <td>0.822474</td>\n",
       "      <td>0.834527</td>\n",
       "      <td>0.00900522</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.812272</td>\n",
       "      <td>0.822473</td>\n",
       "      <td>0.834527</td>\n",
       "      <td>0.00900553</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.812272</td>\n",
       "      <td>0.822473</td>\n",
       "      <td>0.834527</td>\n",
       "      <td>0.00900556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.808609</td>\n",
       "      <td>0.821405</td>\n",
       "      <td>0.833759</td>\n",
       "      <td>0.0085091</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.805951</td>\n",
       "      <td>0.817089</td>\n",
       "      <td>0.82847</td>\n",
       "      <td>0.0084836</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.803969</td>\n",
       "      <td>0.81566</td>\n",
       "      <td>0.825487</td>\n",
       "      <td>0.00860163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.803009</td>\n",
       "      <td>0.817212</td>\n",
       "      <td>0.834801</td>\n",
       "      <td>0.0108513</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.80277</td>\n",
       "      <td>0.821141</td>\n",
       "      <td>0.837047</td>\n",
       "      <td>0.0118104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.79907</td>\n",
       "      <td>0.812229</td>\n",
       "      <td>0.830095</td>\n",
       "      <td>0.011712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.796609</td>\n",
       "      <td>0.81266</td>\n",
       "      <td>0.820524</td>\n",
       "      <td>0.0086255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.795052</td>\n",
       "      <td>0.809023</td>\n",
       "      <td>0.820552</td>\n",
       "      <td>0.00900889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.790487</td>\n",
       "      <td>0.809122</td>\n",
       "      <td>0.817653</td>\n",
       "      <td>0.00972898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.781212</td>\n",
       "      <td>0.800375</td>\n",
       "      <td>0.809897</td>\n",
       "      <td>0.0105556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>0.75398</td>\n",
       "      <td>0.773632</td>\n",
       "      <td>0.796122</td>\n",
       "      <td>0.0152415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.75285</td>\n",
       "      <td>0.765736</td>\n",
       "      <td>0.786662</td>\n",
       "      <td>0.011712</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>0.748177</td>\n",
       "      <td>0.769519</td>\n",
       "      <td>0.797507</td>\n",
       "      <td>0.0177722</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>0.732337</td>\n",
       "      <td>0.75408</td>\n",
       "      <td>0.787582</td>\n",
       "      <td>0.0214334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>0.716277</td>\n",
       "      <td>0.742426</td>\n",
       "      <td>0.768034</td>\n",
       "      <td>0.0172889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>0.69492</td>\n",
       "      <td>0.710689</td>\n",
       "      <td>0.729091</td>\n",
       "      <td>0.0135636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>0.650611</td>\n",
       "      <td>0.657846</td>\n",
       "      <td>0.664229</td>\n",
       "      <td>0.00499186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>0.525079</td>\n",
       "      <td>0.594567</td>\n",
       "      <td>0.680156</td>\n",
       "      <td>0.0569846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>0.265123</td>\n",
       "      <td>0.40995</td>\n",
       "      <td>0.619789</td>\n",
       "      <td>0.133563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>0.165613</td>\n",
       "      <td>0.279681</td>\n",
       "      <td>0.440281</td>\n",
       "      <td>0.119884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>-0.00120432</td>\n",
       "      <td>0.00140649</td>\n",
       "      <td>0.00625206</td>\n",
       "      <td>0.00279519</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>-0.00354328</td>\n",
       "      <td>-0.00112529</td>\n",
       "      <td>-4.27032e-06</td>\n",
       "      <td>0.0012899</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>-0.0461044</td>\n",
       "      <td>0.130693</td>\n",
       "      <td>0.236021</td>\n",
       "      <td>0.0993055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>-0.381013</td>\n",
       "      <td>-0.0200159</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.187398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>-0.461612</td>\n",
       "      <td>-0.0494474</td>\n",
       "      <td>0.362727</td>\n",
       "      <td>0.274115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>-0.584162</td>\n",
       "      <td>0.0256929</td>\n",
       "      <td>0.451685</td>\n",
       "      <td>0.349646</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>-0.727077</td>\n",
       "      <td>0.0683321</td>\n",
       "      <td>0.453554</td>\n",
       "      <td>0.412222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>-0.85624</td>\n",
       "      <td>-0.249825</td>\n",
       "      <td>0.462313</td>\n",
       "      <td>0.486321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    estimator   min_score  mean_score    max_score  \\\n",
       "44        ExtraTreesRegressor    0.848211    0.862127      0.87351   \n",
       "42        ExtraTreesRegressor    0.845945    0.858913     0.869744   \n",
       "43        ExtraTreesRegressor     0.84448    0.860318     0.872867   \n",
       "39      RandomForestRegressor    0.841134    0.854674     0.869205   \n",
       "38      RandomForestRegressor    0.838715    0.854059     0.868475   \n",
       "41        ExtraTreesRegressor    0.837991    0.852692     0.868398   \n",
       "37      RandomForestRegressor     0.83582     0.85235     0.868462   \n",
       "36      RandomForestRegressor    0.831924    0.847105     0.860638   \n",
       "4   GradientBoostingRegressor     0.82505    0.830992     0.839034   \n",
       "2   GradientBoostingRegressor    0.823254    0.831537     0.839264   \n",
       "40        ExtraTreesRegressor    0.821647    0.844716     0.860482   \n",
       "3   GradientBoostingRegressor    0.821635    0.832351     0.841665   \n",
       "35      RandomForestRegressor    0.818883    0.838403     0.855954   \n",
       "7   GradientBoostingRegressor    0.818779    0.825613      0.83594   \n",
       "1   GradientBoostingRegressor    0.817493     0.82569     0.834177   \n",
       "8   GradientBoostingRegressor      0.8135    0.824721     0.837865   \n",
       "18                      Ridge    0.812284    0.822555     0.834493   \n",
       "17                      Ridge    0.812275    0.822483     0.834525   \n",
       "16                      Ridge    0.812273    0.822474     0.834527   \n",
       "15                      Ridge    0.812272    0.822473     0.834527   \n",
       "19           LinearRegression    0.812272    0.822473     0.834527   \n",
       "6   GradientBoostingRegressor    0.808609    0.821405     0.833759   \n",
       "45                      Lasso    0.805951    0.817089      0.82847   \n",
       "0   GradientBoostingRegressor    0.803969     0.81566     0.825487   \n",
       "11  GradientBoostingRegressor    0.803009    0.817212     0.834801   \n",
       "9   GradientBoostingRegressor     0.80277    0.821141     0.837047   \n",
       "5   GradientBoostingRegressor     0.79907    0.812229     0.830095   \n",
       "12  GradientBoostingRegressor    0.796609     0.81266     0.820524   \n",
       "10  GradientBoostingRegressor    0.795052    0.809023     0.820552   \n",
       "13  GradientBoostingRegressor    0.790487    0.809122     0.817653   \n",
       "14  GradientBoostingRegressor    0.781212    0.800375     0.809897   \n",
       "20          AdaBoostRegressor     0.75398    0.773632     0.796122   \n",
       "46                      Lasso     0.75285    0.765736     0.786662   \n",
       "25          AdaBoostRegressor    0.748177    0.769519     0.797507   \n",
       "30          AdaBoostRegressor    0.732337     0.75408     0.787582   \n",
       "21          AdaBoostRegressor    0.716277    0.742426     0.768034   \n",
       "26          AdaBoostRegressor     0.69492    0.710689     0.729091   \n",
       "31          AdaBoostRegressor    0.650611    0.657846     0.664229   \n",
       "22          AdaBoostRegressor    0.525079    0.594567     0.680156   \n",
       "27          AdaBoostRegressor    0.265123     0.40995     0.619789   \n",
       "23          AdaBoostRegressor    0.165613    0.279681     0.440281   \n",
       "47                      Lasso -0.00120432  0.00140649   0.00625206   \n",
       "48                      Lasso -0.00354328 -0.00112529 -4.27032e-06   \n",
       "32          AdaBoostRegressor  -0.0461044    0.130693     0.236021   \n",
       "28          AdaBoostRegressor   -0.381013  -0.0200159     0.142857   \n",
       "33          AdaBoostRegressor   -0.461612  -0.0494474     0.362727   \n",
       "24          AdaBoostRegressor   -0.584162   0.0256929     0.451685   \n",
       "29          AdaBoostRegressor   -0.727077   0.0683321     0.453554   \n",
       "34          AdaBoostRegressor    -0.85624   -0.249825     0.462313   \n",
       "\n",
       "     std_score  alpha learning_rate n_estimators  \n",
       "44   0.0104309    NaN           NaN          128  \n",
       "42      0.0101    NaN           NaN           32  \n",
       "43   0.0117674    NaN           NaN           64  \n",
       "39   0.0121925    NaN           NaN          128  \n",
       "38   0.0118229    NaN           NaN           64  \n",
       "41   0.0124164    NaN           NaN           16  \n",
       "37   0.0129344    NaN           NaN           32  \n",
       "36   0.0120372    NaN           NaN           16  \n",
       "4   0.00517329    NaN           0.6          128  \n",
       "2   0.00555201    NaN           0.6           32  \n",
       "40   0.0150916    NaN           NaN            8  \n",
       "3   0.00660997    NaN           0.6           64  \n",
       "35   0.0149617    NaN           NaN            8  \n",
       "7   0.00639065    NaN           0.8           32  \n",
       "1   0.00658899    NaN           0.6           16  \n",
       "8   0.00889868    NaN           0.8           64  \n",
       "18  0.00897273      1           NaN          NaN  \n",
       "17  0.00900215    0.1           NaN          NaN  \n",
       "16  0.00900522   0.01           NaN          NaN  \n",
       "15  0.00900553  0.001           NaN          NaN  \n",
       "19  0.00900556    NaN           NaN          NaN  \n",
       "6    0.0085091    NaN           0.8           16  \n",
       "45   0.0084836  0.001           NaN          NaN  \n",
       "0   0.00860163    NaN           0.6            8  \n",
       "11   0.0108513    NaN             1           16  \n",
       "9    0.0118104    NaN           0.8          128  \n",
       "5     0.011712    NaN           0.8            8  \n",
       "12   0.0086255    NaN             1           32  \n",
       "10  0.00900889    NaN             1            8  \n",
       "13  0.00972898    NaN             1           64  \n",
       "14   0.0105556    NaN             1          128  \n",
       "20   0.0152415    NaN           0.6            8  \n",
       "46    0.011712   0.01           NaN          NaN  \n",
       "25   0.0177722    NaN           0.8            8  \n",
       "30   0.0214334    NaN             1            8  \n",
       "21   0.0172889    NaN           0.6           16  \n",
       "26   0.0135636    NaN           0.8           16  \n",
       "31  0.00499186    NaN             1           16  \n",
       "22   0.0569846    NaN           0.6           32  \n",
       "27    0.133563    NaN           0.8           32  \n",
       "23    0.119884    NaN           0.6           64  \n",
       "47  0.00279519    0.1           NaN          NaN  \n",
       "48   0.0012899      1           NaN          NaN  \n",
       "32   0.0993055    NaN             1           32  \n",
       "28    0.187398    NaN           0.8           64  \n",
       "33    0.274115    NaN             1           64  \n",
       "24    0.349646    NaN           0.6          128  \n",
       "29    0.412222    NaN           0.8          128  \n",
       "34    0.486321    NaN             1          128  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper1.score_summary(sort_by='min_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
